{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from util import bfs, count_edge_length, count_edge_crossings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In context learning prompts\n",
    "\n",
    "In this notebook we will create a set of prompts to test the in context learning capabilities of ChatGPT when applied to graph visualization problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank assignment prompts\n",
    "\n",
    "We will start with the problem of rank assignment. We will generate the new prompts by randomly sampling 5 graphs from different files, and prepending their correct solutions to the prompt asking for the solution of the current graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_base = \"\"\"\n",
    "Perform a rank assignment on the graph. Use node 0 as a source for the graph. Each node must be assigned to a rank that is equal to the shortest path between that node and the source. Thus, node 0 will be assigned to rank 0, and the neighbors of node 0 will be assigned to rank 1. \n",
    "Write no explanations, only respond with the id of each node and the rank it has been assigned to in a format <id> - <rank>.\\n\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_prompt_query_dir = \"queries/rank_prompts\"\n",
    "all_rank_prompt_files = set(os.listdir(rank_prompt_query_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_prompt_edge_list(query: str) -> list:\n",
    "    rank_prompt_edge_list = (\n",
    "        query.split(\"edge connections:\")[1]\n",
    "        .split(\"Perform a rank assignment\")[0]\n",
    "        .strip()\n",
    "    )\n",
    "    rank_prompt_edge_list = list(ast.literal_eval(rank_prompt_edge_list))\n",
    "    return rank_prompt_edge_list\n",
    "\n",
    "def rank_assignment_to_formatted_str(rank_assignment: dict) -> str:\n",
    "    rank_assignment_str = \"\"\n",
    "    for rank, nodes in rank_assignment.items():\n",
    "        for node in nodes:\n",
    "            rank_assignment_str += f\"{node} - {rank}\\n\"\n",
    "    return rank_assignment_str\n",
    "\n",
    "def minimize_prompt(query: str) -> str:\n",
    "    query = query.split(\"\\n\")\n",
    "    query = query[:-2]\n",
    "    query = \"\\n\".join(query)\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled 100 queries\n"
     ]
    }
   ],
   "source": [
    "k_samples = 3\n",
    "sample_size = 100\n",
    "\n",
    "# Sample `sample_size` queries from the all_rank_prompt_files\n",
    "sampled_rank_prompt_files = np.random.choice(\n",
    "    list(all_rank_prompt_files), sample_size, replace=False\n",
    ")\n",
    "print(f\"Sampled {len(sampled_rank_prompt_files)} queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_prompts_icl = {}\n",
    "\n",
    "for rank_prompt_file in sampled_rank_prompt_files:\n",
    "    # Sample 5 other prompt files different from the current one\n",
    "    other_rank_prompt_files = np.random.choice(\n",
    "        list(all_rank_prompt_files - {rank_prompt_file}), k_samples, replace=False\n",
    "    )\n",
    "    assert rank_prompt_file not in other_rank_prompt_files\n",
    "\n",
    "    # Read the current prompt and the other prompts\n",
    "    rank_prompt = open(os.path.join(rank_prompt_query_dir, rank_prompt_file)).read()\n",
    "    other_rank_prompts = [\n",
    "        open(os.path.join(rank_prompt_query_dir, other_rank_prompt_file)).read()\n",
    "        for other_rank_prompt_file in other_rank_prompt_files\n",
    "    ]\n",
    "\n",
    "    # Extract the edge list for both the current prompt and the other prompts\n",
    "    rank_prompt_edge_list = read_prompt_edge_list(rank_prompt)\n",
    "    other_rank_prompt_edge_lists = [\n",
    "        read_prompt_edge_list(other_rank_prompt)\n",
    "        for other_rank_prompt in other_rank_prompts\n",
    "    ]\n",
    "\n",
    "    # Compute the correct rank assignment for the other prompts\n",
    "    other_rank_prompt_rank_assignments = [\n",
    "        bfs(other_rank_prompt_edge_list, 0)\n",
    "        for other_rank_prompt_edge_list in other_rank_prompt_edge_lists\n",
    "    ]\n",
    "\n",
    "    # Convert the rank assignments in the expected format, i.e. <id> - <rank> one per row\n",
    "    other_rank_prompt_rank_assignments_str = [\n",
    "        rank_assignment_to_formatted_str(other_rank_prompt_rank_assignment)\n",
    "        for other_rank_prompt_rank_assignment in other_rank_prompt_rank_assignments\n",
    "    ]\n",
    "\n",
    "    # Build the prompt\n",
    "    prompt = [\n",
    "        \"Input:\\n{}\\nAnswer:\\n{}\\n\".format(\n",
    "            minimize_prompt(other_rank_prompts[i]),\n",
    "            other_rank_prompt_rank_assignments_str[i],\n",
    "        )\n",
    "        for i in range(k_samples)\n",
    "    ]\n",
    "    prompt = prompt_base + \"\".join(prompt)\n",
    "    prompt += \"Input:\\n{}\\nAnswer:\\n\".format(minimize_prompt(rank_prompt))\n",
    "\n",
    "    # expected_answer = bfs(rank_prompt_edge_list, 0)\n",
    "    # expected_answer_str = rank_assignment_to_formatted_str(expected_answer)\n",
    "\n",
    "    rank_prompts_icl[rank_prompt_file] = prompt.strip()\n",
    "\n",
    "    del rank_prompt, other_rank_prompts, prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_prompts_icl_query_dir = \"queries/rank_prompts_icl\"\n",
    "os.makedirs(rank_prompts_icl_query_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the prompts to disk\n",
    "for rank_prompt_file, prompt in rank_prompts_icl.items():\n",
    "    with open(os.path.join(rank_prompts_icl_query_dir, rank_prompt_file), \"w\") as f:\n",
    "        f.write(prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transpose prompts\n",
    "\n",
    "We can repeat a similar process for the crossing minimization prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_base = \"\"\"We want to reduce crossings on a graph drawing.\n",
    "We want to order the nodes in the layers so that there are few crossings in the graph. \n",
    "- visit every rank once, starting from layer 0\n",
    "- try different transpositions of the nodes in that layer\n",
    "- count the crossings for every transposition. There is a crossing between two edges e1 and e2 if the source of e1 comes before the source of e2, and the target of e1 comes after the target of e2 in the order of nodes in a layer.\n",
    "- record the transposition that produces the least amount of crossings, and sort the nodes accordingly.\n",
    "Nodes can NOT be moved to a different layer. You can only reorder nodes within layers.\n",
    "Write no code and no explanation.\n",
    "Return the layers dictionary with the nodes ordered, in a code block. I want it formatted like this: {<layer_id>:[<list of ordered nodes>]}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transpose_query_dir = \"queries/transpose_prompts3\"\n",
    "all_transpose_files = set(os.listdir(transpose_query_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled 100 queries\n"
     ]
    }
   ],
   "source": [
    "k_samples = 3\n",
    "sample_size = 100\n",
    "\n",
    "# Sample `sample_size` queries from the all_rank_prompt_files\n",
    "sampled_transpose_files = np.random.choice(\n",
    "    list(all_transpose_files), sample_size, replace=False\n",
    ")\n",
    "print(f\"Sampled {len(sampled_transpose_files)} queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of queries:  134\n"
     ]
    }
   ],
   "source": [
    "transpose_queries = {}\n",
    "\n",
    "for query_file in sorted(os.listdir(transpose_query_dir)):\n",
    "    transpose_queries[query_file] = {}\n",
    "    query_file_path = os.path.join(transpose_query_dir, query_file)\n",
    "\n",
    "    query_str = open(query_file_path, \"r\").read().strip()\n",
    "\n",
    "    query_edges = query_str.split(\"edges = \")[1]\n",
    "    query_edges = query_edges.split(\"\\n\")[0].strip()\n",
    "    query_edges = ast.literal_eval(query_edges)\n",
    "\n",
    "    query_ranks = query_str.split(\"ranks = \")[1]\n",
    "    query_ranks = query_ranks.split(\"\\n\\n\")[0].strip()\n",
    "    query_ranks = query_ranks.split(\"\\n\")\n",
    "    # From each substring remove \"Layer \" at the \n",
    "    # beginning and add \",\" at the end\n",
    "    query_ranks = [r[6:].strip() + \",\" for r in query_ranks]\n",
    "    query_ranks = \"\".join(query_ranks)\n",
    "    query_ranks = \"{\" + query_ranks[:-1] + \"}\"\n",
    "    query_ranks = ast.literal_eval(query_ranks)\n",
    "    \n",
    "    transpose_queries[query_file][\"edges\"] = query_edges\n",
    "    transpose_queries[query_file][\"ranks\"] = query_ranks\n",
    "\n",
    "print(\"Number of queries: \", len(transpose_queries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_query_to_str(edges: list, ranks: dict) -> str:\n",
    "    \"\"\"Format a query to a string\"\"\"\n",
    "    query = []\n",
    "    query.append(\"This is the list of edges. Every edge has [<source_id>, <target_id>]:\")\n",
    "    query.append(\"edges = {}\".format(edges))\n",
    "    query.append(\"This is the description of what nodes are contained in what layer: \")\n",
    "    for layer, nodes in ranks.items():\n",
    "        if layer == 0:\n",
    "            query.append(\"ranks = Layer {}: {}\".format(layer, nodes))\n",
    "        else:\n",
    "            query.append(\"Layer {}: {}\".format(layer, nodes))\n",
    "    query = \"\\n\".join(query)\n",
    "    return query\n",
    "\n",
    "def format_ground_truth(ranks: dict) -> str:\n",
    "    \"\"\"Format the ground truth to a string\"\"\"\n",
    "    gt = {int(k): v for k, v in ranks.items()}\n",
    "    \n",
    "    ground_truth = \"{\\n\"\n",
    "    for layer, nodes in gt.items():\n",
    "        ground_truth += f\"{layer}: {nodes},\\n\"\n",
    "    ground_truth = ground_truth[:-2] + \"\\n}\"\n",
    "    return ground_truth\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of queries with ground truth:  207\n"
     ]
    }
   ],
   "source": [
    "# Let's load the ground truth answers for the minimal number of crossings for each query\n",
    "strasifimal_results = json.load(open(\"stratisfimal_results/optimal_ranks_10_11.json\", \"r\"))\n",
    "print(\"Number of queries with ground truth: \", len(strasifimal_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transpose_icl = {}\n",
    "\n",
    "for transpose_file in sampled_transpose_files:\n",
    "    # Sample 5 other prompt files different from the current one\n",
    "    other_transpose_files = np.random.choice(\n",
    "        list(all_transpose_files - {transpose_file}), k_samples, replace=False\n",
    "    )\n",
    "    assert transpose_file not in other_transpose_files\n",
    "\n",
    "    cur_edges = transpose_queries[transpose_file][\"edges\"]\n",
    "    cur_ranks = transpose_queries[transpose_file][\"ranks\"]\n",
    "    other_edges = [\n",
    "        transpose_queries[other_file][\"edges\"] for other_file in other_transpose_files\n",
    "    ]\n",
    "    other_ranks = [\n",
    "        transpose_queries[other_file][\"ranks\"] for other_file in other_transpose_files\n",
    "    ]\n",
    "\n",
    "    ground_truth = strasifimal_results[transpose_file.split(\".txt\")[0]]\n",
    "    other_ground_truth = [\n",
    "        strasifimal_results[other_file.split(\".txt\")[0]]\n",
    "        for other_file in other_transpose_files\n",
    "    ]\n",
    "\n",
    "    cur_query = format_query_to_str(cur_edges, cur_ranks)\n",
    "    other_queries = [\n",
    "        format_query_to_str(other_edges[i], other_ranks[i]) for i in range(k_samples)\n",
    "    ]\n",
    "    other_ground_truth_str = [format_ground_truth(gt) for gt in other_ground_truth]\n",
    "\n",
    "    # print(\"Current query: \", cur_edges, cur_ranks)\n",
    "    # print(\"Other queries: \", other_edges, other_ranks)\n",
    "\n",
    "    # print(format_query_to_str(cur_edges, cur_ranks))\n",
    "    # print(\"Ground truth: \", ground_truth)\n",
    "    # print(format_ground_truth(ground_truth))\n",
    "\n",
    "    # Build the prompt\n",
    "    prompt = [\n",
    "        \"\\nInput:\\n{}\\nAnswer:\\n\\n{}\\n\".format(\n",
    "            other_queries[i],\n",
    "            other_ground_truth_str[i],\n",
    "        )\n",
    "        for i in range(k_samples)\n",
    "    ]\n",
    "    prompt = prompt_base + \"\\n\" + \"\".join(prompt)\n",
    "    prompt += \"\\nInput:\\n{}\\n\\nAnswer:\\n\".format(cur_query)\n",
    "\n",
    "    transpose_icl[transpose_file] = prompt.strip()\n",
    "    del (\n",
    "        cur_edges,\n",
    "        cur_ranks,\n",
    "        other_edges,\n",
    "        other_ranks,\n",
    "        ground_truth,\n",
    "        other_ground_truth,\n",
    "        prompt,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tojs = [i.split(\".txt\")[0].strip() for i in sorted(list(all_transpose_files))]\n",
    "# json.dump(tojs, open(\"transpose_prompts3_files.json\", \"w\"), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transpose_prompts_icl_query_dir = \"queries/transpose_prompts_icl\"\n",
    "os.makedirs(transpose_prompts_icl_query_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the prompts to disk\n",
    "for query_file, prompt in transpose_icl.items():\n",
    "    query_file_path = os.path.join(transpose_prompts_icl_query_dir, query_file)\n",
    "    with open(query_file_path, \"w\") as f:\n",
    "        f.write(prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long edge length prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_edge_prompt_base = \"\"\"A layered graph is a graph where each node is contained in a single layer.\n",
    "A layered graph is described by list of directed edges, formatted as [(<source_id>, <target_id>)], and a mapping of layers to the nodes contained within.\n",
    "Every array in the mapping is a different layer, and the numbers in every array indicate the nodes in that layer.\n",
    "\n",
    "Count the total edge length. \n",
    "The edge length of each edge e is always equal to the absolute value of the number of the layer the target is contained in, minus the number of the layer the source is contained in.\n",
    "The edge length can't be negative.\n",
    "\n",
    "Write no explanations and no code. Return the total sum of the lengths.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of queries:  50\n"
     ]
    }
   ],
   "source": [
    "long_edge_query_dir = \"queries/longer_edge_length_prompts_steps\"\n",
    "all_long_edge_files = set(os.listdir(long_edge_query_dir))\n",
    "print(\"Number of queries: \", len(all_long_edge_files))\n",
    "\n",
    "k_samples = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_long_edge_query(fname:str):\n",
    "    with open(fname, \"r\") as query_file:\n",
    "        query_content = query_file.read().split(\"\\n\")\n",
    "\n",
    "    el = [(int(u), int(v)) for (u, v) in ast.literal_eval(query_content[4].split(\":\")[1].strip())]\n",
    "\n",
    "    try:\n",
    "        nr = {\n",
    "            0 : [int(x) for x in ast.literal_eval(query_content[8].split(\":\")[1].strip())],\n",
    "            1 : [int(x) for x in ast.literal_eval(query_content[9].split(\":\")[1].strip())],\n",
    "            2 : [int(x) for x in ast.literal_eval(query_content[10].split(\":\")[1].strip())],\n",
    "            3 : [int(x) for x in ast.literal_eval(query_content[11].split(\":\")[1].strip())],\n",
    "            4 : [int(x) for x in ast.literal_eval(query_content[12].split(\":\")[1].strip())],\n",
    "            5 : [int(x) for x in ast.literal_eval(query_content[13].split(\":\")[1].strip())],\n",
    "        }\n",
    "    except:\n",
    "        nr = {\n",
    "            0 : [int(x) for x in ast.literal_eval(query_content[8].split(\":\")[1].strip())],\n",
    "            1 : [int(x) for x in ast.literal_eval(query_content[9].split(\":\")[1].strip())],\n",
    "            2 : [int(x) for x in ast.literal_eval(query_content[10].split(\":\")[1].strip())],\n",
    "            3 : [int(x) for x in ast.literal_eval(query_content[11].split(\":\")[1].strip())],\n",
    "            4 : [int(x) for x in ast.literal_eval(query_content[12].split(\":\")[1].strip())],\n",
    "        }\n",
    "\n",
    "    return el, nr\n",
    "\n",
    "def format_query_to_str_long_edge(edges: list, ranks: dict) -> str:\n",
    "    \"\"\"Format a query to a string\"\"\"\n",
    "    query = []\n",
    "    query.append(\"List of edges formatted as [<source_id>, <target_id>]:\")\n",
    "    query.append(\"edges = {}\".format(edges))\n",
    "    query.append(\"Mapping of layers to nodes:\")\n",
    "    for layer, nodes in ranks.items():\n",
    "        if layer == 0:\n",
    "            query.append(\"ranks = Layer {}: {}\".format(layer, nodes))\n",
    "        else:\n",
    "            query.append(\"Layer {}: {}\".format(layer, nodes))\n",
    "    query = \"\\n\".join(query)\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_edge_queries = {}\n",
    "long_edge_gt = {}\n",
    "for query_file in all_long_edge_files:\n",
    "    query_file_path = os.path.join(long_edge_query_dir, query_file)\n",
    "    edges, ranks = read_long_edge_query(query_file_path)\n",
    "    long_edge_queries[query_file] = {\"edges\": edges, \"ranks\": ranks}\n",
    "    gt = count_edge_length(edges, ranks)\n",
    "    long_edge_gt[query_file] = gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_edge_icl = {}\n",
    "for query_file in all_long_edge_files:\n",
    "    long_edge_query = long_edge_queries[query_file]\n",
    "    cur_edges = long_edge_query[\"edges\"]\n",
    "    cur_ranks = long_edge_query[\"ranks\"]\n",
    "    cur_gt = long_edge_gt[query_file]\n",
    "\n",
    "    other_long_edge_files = np.random.choice(\n",
    "        list(all_long_edge_files - {query_file}), k_samples, replace=False\n",
    "    )\n",
    "    assert query_file not in other_long_edge_files\n",
    "\n",
    "    other_queries = [\n",
    "        long_edge_queries[other_file] for other_file in other_long_edge_files\n",
    "    ]\n",
    "    other_edges = [other_query[\"edges\"] for other_query in other_queries]\n",
    "    other_ranks = [other_query[\"ranks\"] for other_query in other_queries]\n",
    "    other_gt = [long_edge_gt[other_file] for other_file in other_long_edge_files]\n",
    "\n",
    "    # Build the prompt\n",
    "    prompt = [\n",
    "        \"\\n## Input:\\n{}\\n## Answer:\\n{}\\n\".format(\n",
    "            format_query_to_str_long_edge(other_edges[i], other_ranks[i]),\n",
    "            other_gt[i],\n",
    "        )\n",
    "        for i in range(k_samples)\n",
    "    ]\n",
    "    prompt = long_edge_prompt_base + \"\".join(prompt)\n",
    "    prompt += \"\\n## Input:\\n{}\\n## Answer:\\n\".format(\n",
    "        format_query_to_str_long_edge(cur_edges, cur_ranks)\n",
    "    )\n",
    "\n",
    "    long_edge_icl[query_file] = prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_edge_icl_query_dir = \"queries/longer_edge_length_prompts_icl\"\n",
    "os.makedirs(long_edge_icl_query_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the prompts to disk\n",
    "for query_file, prompt in long_edge_icl.items():\n",
    "    query_file_path = os.path.join(long_edge_icl_query_dir, query_file)\n",
    "    with open(query_file_path, \"w\") as f:\n",
    "        f.write(prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crossing prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossing_base_prompt = \"\"\"You are a very advanced program that can help me with counting edge crossings in a bipartite graph.\n",
    "I will provide you with the arrays of nodes of layers A and B and a list of edges as tuples.\n",
    "For each edge the first element comes from array A, and the second element comes from array B.\n",
    "\n",
    "Assuming this is a bipartite graph, count the edge crossings. \n",
    "Two edges that share a source or a target can not cross. \n",
    "Two edges cross if the order of their sources is opposite to the order of their targets.\n",
    "\n",
    "Exclude all crossings where edges have the same source or the same target.\n",
    "\n",
    "Write no explanations and no code. Return the number of edges that cross. There might be no edge crossings - in that case, return 0.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_crossing_query(query: str):\n",
    "    query = query.split(\"\\n\")\n",
    "    layer_a_str = query[3]\n",
    "    layer_b_str = query[4]\n",
    "    edges_str = query[7]\n",
    "\n",
    "    layer_a = ast.literal_eval(layer_a_str.split(\"A:\")[1].strip())\n",
    "    layer_b = ast.literal_eval(layer_b_str.split(\"B:\")[1].strip())\n",
    "    edges = ast.literal_eval(edges_str.split(\"Tuples:\")[1].strip())\n",
    "\n",
    "    return edges, {0: layer_a, 1: layer_b}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of crossing queries: 94\n"
     ]
    }
   ],
   "source": [
    "cross_query_dir = \"queries/crossings_prompts_steps\"\n",
    "cross_query_files = set(sorted(os.listdir(cross_query_dir)))\n",
    "print(\"Number of crossing queries: {}\".format(len(cross_query_files)))\n",
    "\n",
    "k_samples = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_queries = {}\n",
    "cross_gt = {}\n",
    "for query_file in cross_query_files:\n",
    "    query_str = open(os.path.join(cross_query_dir, query_file)).read()\n",
    "    edges, ranks = parse_crossing_query(query_str)\n",
    "    gt = count_edge_crossings(edges, ranks)\n",
    "    cross_queries[query_file] = {\"edges\": edges, \"ranks\": ranks}\n",
    "    cross_gt[query_file] = int(gt)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_cross_query(ranks:dict, edges:list):\n",
    "    query = \"Layer arrays:\\n\"\n",
    "    query += \"A: {}\\n\".format(ranks[0])\n",
    "    query += \"B: {}\\n\".format(ranks[1])\n",
    "    query += \"Edge tuples:\\n\"\n",
    "    query += \"Tuples: {}\\n\".format(edges)\n",
    "    return query  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_icl = {}\n",
    "for query_file in cross_query_files:\n",
    "    cross_query = cross_queries[query_file]\n",
    "    cur_edges = cross_query[\"edges\"]\n",
    "    cur_ranks = cross_query[\"ranks\"]\n",
    "    cur_gt = cross_gt[query_file]\n",
    "\n",
    "    other_cross_files = np.random.choice(\n",
    "        list(cross_query_files - {query_file}), k_samples, replace=False\n",
    "    )\n",
    "    assert query_file not in other_cross_files\n",
    "\n",
    "    other_queries = [\n",
    "        cross_queries[other_file] for other_file in other_cross_files\n",
    "    ]\n",
    "    other_edges = [other_query[\"edges\"] for other_query in other_queries]\n",
    "    other_ranks = [other_query[\"ranks\"] for other_query in other_queries]\n",
    "    other_gt = [cross_gt[other_file] for other_file in other_cross_files]\n",
    "\n",
    "    query_str = format_cross_query(cur_ranks, cur_edges)\n",
    "\n",
    "    # Build the prompt\n",
    "    prompt = [\n",
    "        \"\\n## Input:\\n{}\\n## Answer:\\n{}\\n\".format(\n",
    "            format_cross_query(other_ranks[i], other_edges[i]),\n",
    "            other_gt[i],\n",
    "        )\n",
    "        for i in range(k_samples)\n",
    "    ]\n",
    "    prompt = crossing_base_prompt + \"\".join(prompt)\n",
    "    prompt += \"\\n## Input:\\n{}\\n## Answer:\\n\".format(query_str)\n",
    "\n",
    "    cross_icl[query_file] = prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_icl_dir = \"queries/crossings_prompts_icl\"\n",
    "os.makedirs(cross_icl_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the prompts to disk\n",
    "for query_file, prompt in cross_icl.items():\n",
    "    query_file_path = os.path.join(cross_icl_dir, query_file)\n",
    "    with open(query_file_path, \"w\") as f:\n",
    "        f.write(prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt_graphs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dafb023fb61a9cb21231b21edf636d8c395a3f8533b033bfdca443941bcc4563"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
