{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "import hashlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transpose_query_dir_new = \"queries/transpose_prompts3\"\n",
    "transpose_query_dir_old = \"queries/transpose_prompts3_copy\"\n",
    "fname_content_new = {}\n",
    "fname_content_old = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted(os.listdir(transpose_query_dir_old)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in os.listdir(transpose_query_dir_new):\n",
    "    with open(os.path.join(transpose_query_dir_new, fname), \"r\") as f:\n",
    "        fname_content_new[fname] = f.read()\n",
    "\n",
    "for fname in os.listdir(transpose_query_dir_old):\n",
    "    with open(os.path.join(transpose_query_dir_old, fname), \"r\") as f:\n",
    "        fname_content_old[fname] = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_fname_new = {}\n",
    "content_fname_old = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname, content in fname_content_new.items():\n",
    "    md5_content = hashlib.md5(content.encode()).hexdigest()\n",
    "    content_fname_new[md5_content] = fname\n",
    "\n",
    "for fname, content in fname_content_old.items():\n",
    "    md5_content = hashlib.md5(content.encode()).hexdigest()\n",
    "    content_fname_old[md5_content] = fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134\n"
     ]
    }
   ],
   "source": [
    "assert len(content_fname_new) == len(content_fname_old)\n",
    "print(len(content_fname_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n"
     ]
    }
   ],
   "source": [
    "md5_seen = {}\n",
    "duplicated_fnames = {}\n",
    "# Find queries with duplicated content\n",
    "for fname in os.listdir(transpose_query_dir_new):\n",
    "    with open(os.path.join(transpose_query_dir_new, fname), \"r\") as f:\n",
    "        content = f.read()\n",
    "    md5_content = hashlib.md5(content.encode()).hexdigest()\n",
    "    if md5_content in md5_seen:\n",
    "        duplicated_fnames[fname] = md5_seen[md5_content]\n",
    "    else:\n",
    "        md5_seen[md5_content] = fname\n",
    "\n",
    "print(len(duplicated_fnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_to_new_fnames = {}\n",
    "for content, fname_old in content_fname_old.items():\n",
    "    fname_new = content_fname_new[content]\n",
    "    old_to_new_fnames[fname_old] = fname_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname1, fname2 in duplicated_fnames.items():\n",
    "    fname1 = fname1.split(\".txt\")[0]\n",
    "    fname2 = fname2.split(\".txt\")[0]\n",
    "    original_rome_content1 = open(os.path.join(\"rome\", fname1 + \".graphml\"), \"r\").read().strip()\n",
    "    original_rome_content2 = open(os.path.join(\"rome\", fname2 + \".graphml\"), \"r\").read().strip()\n",
    "    original_rome_content1_md5 = hashlib.md5(original_rome_content1.encode()).hexdigest()\n",
    "    original_rome_content2_md5 = hashlib.md5(original_rome_content2.encode()).hexdigest()\n",
    "    assert original_rome_content1_md5 == original_rome_content2_md5, \"{} != {}\".format(fname1, fname2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json.dump(duplicated_fnames, open(\"duplicated_fnames.json\", \"w\"), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the file names for the resposne files\n",
    "# response_dir = \"responses/transpose_prompts3\"\n",
    "\n",
    "# start_point = \"Sara Di Bartolomeo\"\n",
    "# split_point = \"{<layer_id>:[<list of ordered nodes>]}\"\n",
    "\n",
    "# for fname in os.listdir(response_dir):\n",
    "#     fcontent = open(os.path.join(response_dir, fname), \"r\").read()\n",
    "#     fcontent = fcontent.split(start_point)[1].split(split_point)[0].strip()\n",
    "#     fcontent += \" \" + split_point\n",
    "#     fcontent = fcontent.strip()\n",
    "#     fcontent_md5 = hashlib.md5(fcontent.encode()).hexdigest()\n",
    "\n",
    "#     assert fcontent_md5 in content_fname_new\n",
    "\n",
    "#     fname_new = content_fname_new[fcontent_md5]\n",
    "    \n",
    "#     shutil.move(os.path.join(response_dir, fname), os.path.join(response_dir, fname_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_prompts_dir = \"queries/rank_prompts\"\n",
    "all_rank_prompts = sorted(os.listdir(rank_prompts_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n"
     ]
    }
   ],
   "source": [
    "duplicates_rank_prompts = []\n",
    "for fname in duplicated_fnames.keys():\n",
    "    if fname in all_rank_prompts:\n",
    "        os.remove(os.path.join(rank_prompts_dir, fname))\n",
    "        duplicates_rank_prompts.append(fname)\n",
    "\n",
    "print(len(duplicates_rank_prompts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_prompts_response_dir = \"responses/rank_prompts\"\n",
    "all_rank_prompts_response = sorted(os.listdir(rank_prompts_response_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n"
     ]
    }
   ],
   "source": [
    "duplicate_rank_prompts_response = []\n",
    "for fname in duplicated_fnames.keys():\n",
    "    if fname in all_rank_prompts_response:\n",
    "        os.remove(os.path.join(rank_prompts_response_dir, fname))\n",
    "        duplicate_rank_prompts_response.append(fname)\n",
    "\n",
    "print(len(duplicate_rank_prompts_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207\n"
     ]
    }
   ],
   "source": [
    "edge_length_dir = \"queries/edge_length_prompts\"\n",
    "all_edge_length = sorted(os.listdir(edge_length_dir))\n",
    "print(len(all_edge_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    }
   ],
   "source": [
    "duplicate_edge_length = []\n",
    "for fname in duplicated_fnames.keys():\n",
    "    if fname in all_edge_length:\n",
    "        os.remove(os.path.join(edge_length_dir, fname))\n",
    "        duplicate_edge_length.append(fname)\n",
    "\n",
    "print(len(duplicate_edge_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207\n"
     ]
    }
   ],
   "source": [
    "edge_length_response_dir = \"responses/edge_length_prompts\"\n",
    "all_edge_length_response = sorted(os.listdir(edge_length_response_dir))\n",
    "print(len(all_edge_length_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    }
   ],
   "source": [
    "duplicate_edge_length_response = []\n",
    "for fname in duplicated_fnames.keys():\n",
    "    if fname in all_edge_length_response:\n",
    "        os.remove(os.path.join(edge_length_response_dir, fname))\n",
    "        duplicate_edge_length_response.append(fname)\n",
    "\n",
    "print(len(duplicate_edge_length_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207\n"
     ]
    }
   ],
   "source": [
    "transpose_query_dir_new\n",
    "all_transpose_new = sorted(os.listdir(transpose_query_dir_new))\n",
    "print(len(all_transpose_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n"
     ]
    }
   ],
   "source": [
    "duplicate_transpose_new = []\n",
    "for fname in duplicated_fnames.keys():\n",
    "    if fname in all_transpose_new:\n",
    "        os.remove(os.path.join(transpose_query_dir_new, fname))\n",
    "        duplicate_transpose_new.append(fname)\n",
    "\n",
    "print(len(duplicate_transpose_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134\n",
      "grafo1070.10.txt -> grafo465.10.txt\n",
      "grafo1774.10.txt -> grafo1657.10.txt\n",
      "grafo2809.11.txt -> grafo2812.11.txt\n",
      "grafo462.10.txt -> grafo210.10.txt\n",
      "grafo751.11.txt -> grafo1100.11.txt\n",
      "grafo782.10.txt -> grafo1032.10.txt\n",
      "grafo997.11.txt -> grafo1006.11.txt\n"
     ]
    }
   ],
   "source": [
    "transpose_query_responses = \"responses/transpose_prompts3\"\n",
    "all_transpose_new = sorted(os.listdir(transpose_query_responses))\n",
    "print(len(all_transpose_new))\n",
    "sources = []\n",
    "destinations = []\n",
    "for fname in all_transpose_new:\n",
    "    if fname in duplicated_fnames.keys():\n",
    "        print(fname, \"->\", duplicated_fnames[fname])\n",
    "        sources.append(fname)\n",
    "        destinations.append(duplicated_fnames[fname])\n",
    "\n",
    "for dest in destinations:\n",
    "    assert dest not in all_transpose_new\n",
    "\n",
    "assert len(sources) == len(destinations)\n",
    "\n",
    "for i in  range(len(sources)):\n",
    "    shutil.move(os.path.join(transpose_query_responses, sources[i]), os.path.join(transpose_query_responses, destinations[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt_graphs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dafb023fb61a9cb21231b21edf636d8c395a3f8533b033bfdca443941bcc4563"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
