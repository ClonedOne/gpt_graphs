{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "import hashlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transpose_query_dir_new = \"queries/transpose_prompts3\"\n",
    "transpose_query_dir_old = \"queries/transpose_prompts3_copy\"\n",
    "fname_content_new = {}\n",
    "fname_content_old = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted(os.listdir(transpose_query_dir_old)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in os.listdir(transpose_query_dir_new):\n",
    "    with open(os.path.join(transpose_query_dir_new, fname), \"r\") as f:\n",
    "        fname_content_new[fname] = f.read()\n",
    "\n",
    "for fname in os.listdir(transpose_query_dir_old):\n",
    "    with open(os.path.join(transpose_query_dir_old, fname), \"r\") as f:\n",
    "        fname_content_old[fname] = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_fname_new = {}\n",
    "content_fname_old = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname, content in fname_content_new.items():\n",
    "    md5_content = hashlib.md5(content.encode()).hexdigest()\n",
    "    content_fname_new[md5_content] = fname\n",
    "\n",
    "for fname, content in fname_content_old.items():\n",
    "    md5_content = hashlib.md5(content.encode()).hexdigest()\n",
    "    content_fname_old[md5_content] = fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134\n"
     ]
    }
   ],
   "source": [
    "assert len(content_fname_new) == len(content_fname_old)\n",
    "print(len(content_fname_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_to_new_fnames = {}\n",
    "for content, fname_old in content_fname_old.items():\n",
    "    fname_new = content_fname_new[content]\n",
    "    old_to_new_fnames[fname_old] = fname_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n"
     ]
    }
   ],
   "source": [
    "md5_seen = {}\n",
    "duplicated_fnames = {}\n",
    "# Find queries with duplicated content\n",
    "for fname in os.listdir(transpose_query_dir_new):\n",
    "    with open(os.path.join(transpose_query_dir_new, fname), \"r\") as f:\n",
    "        content = f.read()\n",
    "    md5_content = hashlib.md5(content.encode()).hexdigest()\n",
    "    if md5_content in md5_seen:\n",
    "        duplicated_fnames[fname] = md5_seen[md5_content]\n",
    "    else:\n",
    "        md5_seen[md5_content] = fname\n",
    "\n",
    "print(len(duplicated_fnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname1, fname2 in duplicated_fnames.items():\n",
    "    fname1 = fname1.split(\".txt\")[0]\n",
    "    fname2 = fname2.split(\".txt\")[0]\n",
    "    original_rome_content1 = open(os.path.join(\"rome\", fname1 + \".graphml\"), \"r\").read().strip()\n",
    "    original_rome_content2 = open(os.path.join(\"rome\", fname2 + \".graphml\"), \"r\").read().strip()\n",
    "    original_rome_content1_md5 = hashlib.md5(original_rome_content1.encode()).hexdigest()\n",
    "    original_rome_content2_md5 = hashlib.md5(original_rome_content2.encode()).hexdigest()\n",
    "    assert original_rome_content1_md5 == original_rome_content2_md5, \"{} != {}\".format(fname1, fname2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the file names for the resposne files\n",
    "# response_dir = \"responses/transpose_prompts3\"\n",
    "\n",
    "# start_point = \"Sara Di Bartolomeo\"\n",
    "# split_point = \"{<layer_id>:[<list of ordered nodes>]}\"\n",
    "\n",
    "# for fname in os.listdir(response_dir):\n",
    "#     fcontent = open(os.path.join(response_dir, fname), \"r\").read()\n",
    "#     fcontent = fcontent.split(start_point)[1].split(split_point)[0].strip()\n",
    "#     fcontent += \" \" + split_point\n",
    "#     fcontent = fcontent.strip()\n",
    "#     fcontent_md5 = hashlib.md5(fcontent.encode()).hexdigest()\n",
    "\n",
    "#     assert fcontent_md5 in content_fname_new\n",
    "\n",
    "#     fname_new = content_fname_new[fcontent_md5]\n",
    "    \n",
    "#     shutil.move(os.path.join(response_dir, fname), os.path.join(response_dir, fname_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(os.listdir(\"responses/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt_graphs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dafb023fb61a9cb21231b21edf636d8c395a3f8533b033bfdca443941bcc4563"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
